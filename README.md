#ğŸ›ï¸ Retail Data Management with AWS Glue

A sample ETL project demonstrating how to use **AWS Glue** to extract, transform, and load retail data stored in Amazon S3.

## â­ï¸ About This Project?

* Configure AWS Glue **Classifiers**, **Crawlers**, and **Visual ETL** jobs
* Understand **best practices** for working with CSV and Parquet in AWS
* Get handsâ€‘on with:

  * **Joining** datasets
  * **Cleaning** currency values with **Regex**
  * **Aggregating** data for analytics
  * **Querying** Parquet outputs with **S3 Select**

## ğŸ“ Repository Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ transactions.csv
â”‚   â””â”€â”€ product details.csv
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ glue_crawlers_setup.md    # Manual steps to configure classifiers & crawlers
â”‚   â”œâ”€â”€ glue_visual_job_diagram.png
â”‚   â””â”€â”€ job_script_export.json    # Exported ETL job definition template
â”œâ”€â”€ output/
â”‚   â””â”€â”€ run-*.parquet            # Sample output file
â””â”€â”€ README.md                    # This file
```

## ğŸš€ Manual Setup in AWS Glue (Simplilearn Account)

1. **Upload data to S3**:

   * Create bucket `etl-cep-01`
   * Create subfolders `transaction-files/` and `product-files/`
   * Upload `transactions.csv` and `product details.csv` from the `data/` folder

2. **Set up AWS Glue**:

   * Create database: `abc-retail`
   * Create two CSV classifiers:

     * `txnClass` for transactions
     * `cust_classifier` for product details
   * Create IAM role `glue-role` with `AdministratorAccess`

3. **Configure Crawlers**:

   * **Crawler** `retail-crawl-txn` â†’ Path `transaction-files/` â†’ Classifier `txnClass`
   * **Crawler** `retail-crawl-product` â†’ Path `product-files/` â†’ Classifier `cust_classifier`

4. **Build Visual ETL Job**:

   * Add Glue Data Catalog nodes for both tables
   * **Join** node (Inner join on `Product ID`)
   * **Drop Fields** (drop duplicate `Product ID`)
   * **Regex Extractor** (`Sales` â†’ `NetSales`, regex `\d+(\.\d+)?`)
   * **Aggregate** (group by `Product Category`, `Ship Mode`; avg of `NetSales`)
   * **Amazon S3** target (bucket `etl-cep-output-01`, format Parquet, compression Snappy)

5. **Run the Job** and verify output in S3:

   * Output file: `run-*.parquet`
   * Use S3 Select to query:

     ```sql
     SELECT * FROM s3object
     ```

## ğŸ“– Additional Documentation

* See [etl/glue\_crawlers\_setup.md](etl/glue_crawlers_setup.md) for detailed manual setup steps.
* See `etl/glue_visual_job_diagram.png` for the ETL flow diagram.

## ğŸ“ Contributing

Feel free to open issues or pull requests to improve data variety, add tests, or enhance documentation.

## ğŸ“œ License

MIT License â€” see [LICENSE](LICENSE).

